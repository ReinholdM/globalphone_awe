{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandox: QbE keyword lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Herman Kamper, Stellenbosch University, 2018-2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from collections import Counter\n",
    "from os import path\n",
    "import codecs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_keywords_fn = \"../features/mfcc/HA/ha.dev.gt_words.npz\"\n",
    "test_fn = \"../features/mfcc/HA/ha.eval.npz\"\n",
    "dev_keywords_features = np.load(dev_keywords_fn)\n",
    "test_features = np.load(test_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_forced_alignment(globalphone_fa_fn):\n",
    "    \"\"\"Return a dictionary of transcriptions obtained from a GlobalPhone forced alignment file.\"\"\"\n",
    "    transcription_dict = {}\n",
    "    with codecs.open(globalphone_fa_fn, \"r\", \"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split(\" \")\n",
    "            utterance_key = line[0]\n",
    "            label = line[4].lower()\n",
    "            if utterance_key not in transcription_dict:\n",
    "                transcription_dict[utterance_key] = []\n",
    "            transcription_dict[utterance_key].append(label)\n",
    "    return transcription_dict    \n",
    "\n",
    "test_transcription = read_forced_alignment(\"/home/kamperh/endgame/datasets/globalphone_alignments/HA/eval.ctm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_counter = Counter()\n",
    "for utterance_key in test_transcription:\n",
    "    for word in test_transcription[utterance_key]:\n",
    "        test_counter[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. words more than 9: 111\n"
     ]
    }
   ],
   "source": [
    "n = 9\n",
    "more_than_n = set()\n",
    "for word, count in test_counter.most_common():\n",
    "    if count >= n:\n",
    "        more_than_n.add(word)\n",
    "print(\"No. words more than {}: {}\".format(n, len(more_than_n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_counter = Counter()\n",
    "dev_words = set()\n",
    "for segment_key in dev_keywords_features:\n",
    "    word = segment_key.split(\"_\")[0].lower()\n",
    "    dev_counter[word] += 1\n",
    "    dev_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. words overlap: 33\n",
      "aikin: 6 times in dev\n",
      "amfani: 8 times in dev\n",
      "amurka: 6 times in dev\n",
      "arziki: 2 times in dev\n",
      "babban: 2 times in dev\n",
      "bayan: 6 times in dev\n",
      "bayyana: 5 times in dev\n",
      "birnin: 7 times in dev\n",
      "cikin: 3 times in dev\n",
      "daban: 1 times in dev\n",
      "daular: 6 times in dev\n",
      "domin: 2 times in dev\n",
      "duniya: 8 times in dev\n",
      "hankali: 7 times in dev\n",
      "hanyar: 5 times in dev\n",
      "harkokin: 12 times in dev\n",
      "kasance: 6 times in dev\n",
      "kasar: 14 times in dev\n",
      "kasashe: 4 times in dev\n",
      "kasashen: 13 times in dev\n",
      "lokacin: 12 times in dev\n",
      "majalisar: 8 times in dev\n",
      "mutane: 18 times in dev\n",
      "samun: 5 times in dev\n",
      "sarki: 7 times in dev\n",
      "sosai: 25 times in dev\n",
      "tattalin: 4 times in dev\n",
      "tsakanin: 11 times in dev\n",
      "wajen: 2 times in dev\n",
      "wanda: 1 times in dev\n",
      "wannan: 5 times in dev\n",
      "zaman: 1 times in dev\n",
      "zamanin: 9 times in dev\n"
     ]
    }
   ],
   "source": [
    "overlap = more_than_n.intersection(dev_words)\n",
    "print(\"No. words overlap:\", len(overlap))\n",
    "for word in sorted(overlap):\n",
    "    print(\"{}: {} times in dev\".format(word, dev_counter[word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_keywords = 30\n",
    "keywords = list(overlap)\n",
    "random.seed(1)\n",
    "random.shuffle(keywords)\n",
    "keywords = keywords[:n_keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords: ['amfani', 'amurka', 'arziki', 'babban', 'bayan', 'bayyana', 'birnin', 'daban', 'daular', 'domin', 'duniya', 'hankali', 'hanyar', 'harkokin', 'kasar', 'kasashe', 'kasashen', 'lokacin', 'majalisar', 'mutane', 'samun', 'sarki', 'sosai', 'tattalin', 'tsakanin', 'wajen', 'wanda', 'wannan', 'zaman', 'zamanin']\n",
      "No. keywords: 30\n"
     ]
    }
   ],
   "source": [
    "print(\"Keywords:\", sorted(keywords))\n",
    "print(\"No. keywords:\", len(keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(\"keywords.txt\", \"w\", \"utf-8\") as f:\n",
    "    for keyword in sorted(keywords):\n",
    "        f.write(keyword + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
